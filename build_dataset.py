import pandas as pd
import glob
import os
import numpy as np

# ================= é…ç½®é¡¹ =================
# CSV æ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ (å¦‚æœè„šæœ¬å°±åœ¨åŒçº§ç›®å½•ï¼Œç”¨ '.' å³å¯)
DATA_DIR = './processed' 
# æƒ³è¦ç”Ÿæˆçš„æ–‡ä»¶å
OUTPUT_FILE = './data/G28_RawPrice.txt'
# =========================================

def main():
    # 1. å¯»æ‰¾æ–‡ä»¶å¤¹é‡Œæ‰€æœ‰çš„ csv æ–‡ä»¶
    # å‡è®¾æ‚¨çš„æ–‡ä»¶åæ ¼å¼ç±»ä¼¼ "AUDNZD_Processed_1H.csv"
    csv_files = glob.glob(os.path.join(DATA_DIR, "*_Processed_1H.csv"))
    
    if len(csv_files) == 0:
        print("âŒ é”™è¯¯ï¼šåœ¨å½“å‰ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ååŒ…å« '_Processed_1H.csv' çš„æ–‡ä»¶ï¼")
        return

    print(f"ğŸ” æ‰¾åˆ°äº† {len(csv_files)} ä¸ªæ•°æ®æ–‡ä»¶ï¼Œå‡†å¤‡å¼€å§‹åˆå¹¶...")
    
    # ç”¨äºå­˜æ”¾æ‰€æœ‰è´§å¸å¯¹æ•°æ®çš„åˆ—è¡¨
    series_list = []
    
    for file_path in sorted(csv_files):
        # æå–è´§å¸å¯¹åç§°ï¼Œä¾‹å¦‚ä» "AUDNZD_Processed_1H.csv" ä¸­æå– "AUDNZD"
        filename = os.path.basename(file_path)
        pair_name = filename.split('_')[0] 
        print(f"   -> æ­£åœ¨è¯»å–: {pair_name} ...")
        
        try:
            # è¯»å– CSV
            df = pd.read_csv(file_path)
            
            # ç¡®ä¿ 'time' åˆ—æ˜¯æ—¶é—´æ ¼å¼ï¼Œå¹¶è®¾ä¸ºç´¢å¼•
            df['time'] = pd.to_datetime(df['time'])
            df.set_index('time', inplace=True)
            
            # åªå– 'Close' åˆ—ï¼Œå¹¶é‡å‘½åä¸ºè´§å¸å¯¹åç§°
            close_series = df[['Close']].rename(columns={'Close': pair_name})
            
            # å»é™¤é‡å¤çš„æ—¶é—´ç´¢å¼• (ä»¥é˜²ä¸‡ä¸€)
            close_series = close_series[~close_series.index.duplicated(keep='first')]
            
            series_list.append(close_series)
            
        except Exception as e:
            print(f"âš ï¸ è¯»å– {filename} æ—¶å‡ºé”™: {e}")

    # 2. åˆå¹¶æ•°æ® (Merge)
    # ä½¿ç”¨ outer join ç¡®ä¿å¹¶é›†ï¼Œä¿è¯æ—¶é—´è½´æ˜¯å®Œæ•´çš„
    print("â³ æ­£åœ¨æŒ‰æ—¶é—´è½´å¯¹é½åˆå¹¶...")
    final_df = pd.concat(series_list, axis=1)
    
    # æŒ‰æ—¶é—´æ’åº
    final_df.sort_index(inplace=True)
    
    print(f"   åŸå§‹æ•°æ®å½¢çŠ¶: {final_df.shape} (è¡Œ=æ—¶é—´, åˆ—=è´§å¸å¯¹)")
    
    # 3. å¤„ç†ç¼ºå¤±å€¼ (Data Cleaning)
    # å¤–æ±‡æ•°æ®å› ä¸ºå‘¨æœ«ä¼‘å¸‚ï¼Œå¤§å®¶åº”è¯¥éƒ½æ˜¯ç©ºçš„ï¼Œå¯ä»¥drop
    # æˆ–è€…æŸäº›æ—¶åˆ»ä¸ªåˆ«è´§å¸ç¼ºå¤±ï¼Œç”¨ ffill (å‰å‘å¡«å……)
    
    # ç­–ç•¥ï¼šå…ˆç”¨å‰å‘å¡«å……(fill forward)è¡¥å…¨å¶å°”çš„äº¤æ˜“ç¼ºå¤±
    final_df.fillna(method='ffill', inplace=True)
    # å†ç”¨åå‘å¡«å……(back fill)è¡¥å…¨å¼€å¤´å¯èƒ½çš„ç¼ºå¤±
    final_df.fillna(method='bfill', inplace=True)
    
    # å¦‚æœè¿˜æœ‰æ•´è¡Œéƒ½æ˜¯ç©ºçš„(æ¯”å¦‚å‘¨æœ«)ï¼Œç›´æ¥ä¸¢å¼ƒ
    original_len = len(final_df)
    final_df.dropna(axis=0, how='any', inplace=True)
    print(f"   å»é™¤åŒ…å« NaN çš„è¡Œåå½¢çŠ¶: {final_df.shape} (åˆ é™¤äº† {original_len - len(final_df)} è¡Œ)")

    # 4. ä¿å­˜ä¸º txt æ–‡ä»¶
    # header=False (ä¸ä¿å­˜åˆ—å), index=False (ä¸ä¿å­˜æ—¶é—´åˆ—)
    # MTGNN åªè¦çº¯æ•°å­—çŸ©é˜µ
    final_df.to_csv(OUTPUT_FILE, sep=',', header=False, index=False)
    
    print("="*30)
    print(f"âœ… å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜ä¸º: {OUTPUT_FILE}")
    print(f"ğŸ“Š æœ€ç»ˆçŸ©é˜µå¤§å°: {final_df.shape}")
    print("   (è¡Œæ•°åº”å½“ä½œä¸º seq_in_len çš„å‚è€ƒï¼Œåˆ—æ•°åº”ä¸º 28)")
    print("="*30)
    
    # ç®€å•æ£€æŸ¥ä¸€ä¸‹ç”Ÿæˆçš„æ•°æ®
    # print(final_df.head())

if __name__ == "__main__":
    main()